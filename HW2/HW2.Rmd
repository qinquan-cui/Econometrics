---
title: "R Notebook"
output: html_notebook
---

# Last update: 09/11/2022
# By: @qinquan cui
# email: qcui@london.edu; quark.tsui@gmail.com

################ Question 1(d) #######################
$$
x_t = \mathrm{log}(SP_t/SP_0)
$$

```{r load-package1}
library(pacman)
p_load(data.table, fixest, lattice, magrittr, ggplot2, kableExtra, xlsx)
```


```{r create index}
## Define my working directory
setwd("~/Documents/R_quark/P218-Econometrics")
SP <- read.xlsx("SP500Index.xlsx", 1)

## options(digits=4) # define the digit of numbers
# Compute the index
SP$index <- log(SP[, 2]/SP[1, 2])
SP$month <- c(0:701)
SP_index1 <- SP[-1, ]
SP_index2 <- SP[-702, ]

```


# Step 1: Derive the likelihood function
```{r step-1}
sigma_2 = 1

log_like <- function(theta, Y, X){
  Y <- as.matrix(SP_index1$index)
  X <- as.matrix(SP_index2$index)
  t <- SP_index1$month
  T <- dim(SP_index1)[1]
  delta   <- theta[1]
  sigma_2 <- theta[2]
  e <- Y-X-delta
  loglik <- -0.5*T*log(2*pi) - 0.5*T*log(sigma_2) - ( (t(e) %*% e)/ (2*sigma_2) )
  return(-loglik)
}
```


# Step 2: Graph the likelihood function
```{r step-2}
log_like_graph <- function(delta, sigma_2){
  Y <- as.matrix(SP_index1$index)
  X <- as.matrix(SP_index2$index)
  t <- SP_index1$month
  T <- dim(SP_index1)[1]
  e <- Y-X-delta
  loglik <- -0.5*T*log(2*pi) - 0.5*T*log(sigma_2) - ( (t(e) %*% e)/ (2*sigma_2) ) 
  return(loglik)
}
log_like_graph <- Vectorize(log_like_graph)

## set grid sigma and sigma values
delta_vals  <- seq(-10, 10, by=1)
sigma2_vals <- seq(1, 10, by=1)
log_vals <- outer(delta_vals, sigma2_vals, log_like_graph)

persp(delta_vals, sigma2_vals, log_vals, theta=7, phi=8, r=500)

```

# Step 3: Find MLS estimates
```{r step-3}
MLE_estimates <- optim(fn = log_like,                 # Likelihood function
                       par = c(0.001,1),              # Initial guess
                       #lower = c(-Inf, -Inf),        # Lower bound on parameters
                       lower = c(-Inf, 0.0001), 
                       upper = c(Inf, Inf),           # Upper bound on parameters
                       hessian = TRUE,                # Return Hessian for SEs
                       method = "L-BFGS-B",
                       # Custom Inputs
                       Y = SP_index1$index,
                       X = SP_index2$index)

## Examine estimates
MLE_par <- MLE_estimates$par
MLE_SE <- sqrt(diag(solve(MLE_estimates$hessian)))
MLE <- data.table(param = c("delta", "sigma_2"),
                  estimates = MLE_par,
                  sd = MLE_SE)

kable(MLE)

```
################ Question 2 #######################
## Testing the assumption of a linear conditional expectation function
```{r load-package2}
library(pacman)
p_load(fastDummies)
```


```{r create dummy variables}
edu_wage <- read.table("ps2.dat",header=TRUE)

edu_wage$experience <- edu_wage[,3]-edu_wage[,2]-6
edu_wage$log_wage   <- log(edu_wage[,1]) 

lwage <- as.matrix(edu_wage$log_wage)
educ  <- as.matrix(edu_wage$ed0)
exper <- as.matrix(edu_wage$experience)

dat_dummy1 = dummy_cols(edu_wage, select_columns=c("ed0"), remove_most_frequent_dummy=FALSE, remove_selected_columns = FALSE, remove_first_dummy=FALSE) 
dat_dummy2 = dummy_cols(edu_wage, select_columns=c("experience"), remove_most_frequent_dummy=FALSE, remove_first_dummy=FALSE) 
dum_ed     = as.matrix( subset(dat_dummy1, select = -c(w0,ed0,a0,experience,log_wage, ed0_1) ) )
dum_exper  = as.matrix( subset(dat_dummy2, select = -c(w0,ed0,a0,experience,log_wage, experience_0) ) )

options(digits=5)
reg_dat    <- lm(lwage ~ dum_ed + dum_exper)
summary(reg_dat)
# cor(dum_expr)
# stargazer(reg_dat, type="latex", title="Regression results of dummy variables")

```
################ Question 3 #######################
# Monte Carlo simulation
```{r preload package3}
library(pacman)
pacman::p_load(data.table, fixest, stargazer, dplyr, magrittr, latex2exp, ggplot2, tidyr, reshape2, MASS) 
```


```{r OLS-Monte Carlo: unbiased and consistent}
## Parameters and seed
beta_0 = 1   # Intercept 
beta_1 = 0.5 # Slope
set.seed(12) # Seed
M = 500      # Number of experiments/iterations
n = seq(from=100, to=5000, by=100)  # the test sample sizes
N = length(n)                       # count them
## Storage 
slope_DT <- matrix(NA, M, N)
intercept_DT <- matrix(NA, M, N)
sympt_DT <- matrix(NA, M, N)
SSR_DT <- matrix(NA, M, N) # SSR/(n-k)

## Begin Monte Carlo
for (n_t in 1:N){
for (i in 1:M){ # M is the number of iterations
  
  # Generate data
  U_i = runif(n[n_t], min = -1, max = 1) # Error
  X_i = rchisq(n[n_t], df = 3)           # Independent variable
  Y_i = beta_0 + beta_1*X_i + U_i        # Dependent variable
  
  # Formulate data.table
  data_i = data.table(Y = Y_i, X = X_i)
  
  # Run regressions
  ols_i <- fixest::feols(data = data_i, Y ~ X)
  
  # Extract slope coefficient and save
  slope_DT[i,n_t] <- ols_i$coefficients[2]
  intercept_DT[i,n_t] <- ols_i$coefficients[1]
  sympt_DT[i,n_t] <- (ols_i$coefficients[2]-beta_1)*sqrt(n[n_t])
  resids <- resid(ols_i)
  SSR_DT[i,n_t] <- sum(resids^2)/(n[n_t]-2)  #SSR/(n-k)
}
}

## Visual inspection ##
## Mean 
par(mfrow = c(1,2), mar = c(4.3,5,1,2))
# beta_1
plot( apply(slope_DT, 2, mean) ~ n, type = "l",
     xlab = "The sample size",
     ylab = TeX(r'(The mean of $\hat{\beta}_1$)'), ylim = c(0.49,0.51), lwd = 1.5 )
abline(h=0.5, col = "blue", lwd = 0.3)
# beta_0
plot( apply(intercept_DT, 2, mean) ~ n, type = "l",
     xlab = "The sampe size",
     ylab = TeX(r'(The mean of $\hat{\beta}_0$)'), ylim = c(0.98,1.02), lwd = 1.5 ) 
abline(h=1, col = "blue", lwd = 0.3)

## Standard Deviation 
par(mfrow = c(1,2), mar = c(4.3,5,1,2))
# beta_1
plot( apply(slope_DT, 2, sd) ~ n, type = "l",
     xlab = "The sample size",
     ylab = TeX(r'(The standard deviation of $\hat{\beta}_1$)'), ylim = c(0,0.03), lwd = 1.5 )

# beta_0
plot( apply(intercept_DT, 2, sd) ~ n, type = "l",
     xlab = "The sampe size",
     ylab = TeX(r'(The standard deviation of $\hat{\beta}_0$)'), ylim = c(0,0.1), lwd = 1.5 ) 

## Summary statistics
# beta_1
est_slope <- data.table(slope_DT)
stargazer(est_slope, type = "text")
# beta_0
est_intercept <- data.table(intercept_DT)
stargazer(est_intercept, type = "text")

```


```{r OLS-Monte Carlo: asymptotically normal}
## Parameters and seed
beta_0 = 1   # Intercept 
beta_1 = 0.5 # Slope
set.seed(9)  # Seed
M = 500      # Number of experiments/iterations
n = c(20, 40, 200, 1000, 9000)      # the test sample sizes
N = length(n)                       # count them
## Storage 
slope_DT <- matrix(NA, M, N)
intercept_DT <- matrix(NA, M, N)
sympt_DT <- matrix(NA, M, N)
SSR_DT <- matrix(NA, M, N) # SSR/(n-k)

## Begin Monte Carlo
for (n_t in 1:N){
for (i in 1:M){ # M is the number of iterations
  
  # Generate data
  U_i = runif(n[n_t], min = -1, max = 1) # Error
  X_i = rchisq(n[n_t], df = 3)           # Independent variable
  Y_i = beta_0 + beta_1*X_i + U_i        # Dependent variable
  
  # Formulate data.table
  data_i = data.table(Y = Y_i, X = X_i)
  
  # Run regressions
  ols_i <- fixest::feols(data = data_i, Y ~ X)
  
  # Extract slope coefficient and save
  slope_DT[i,n_t] <- ols_i$coefficients[2]
  intercept_DT[i,n_t] <- ols_i$coefficients[1]
  sympt_DT[i,n_t] <- (ols_i$coefficients[2]-beta_1)*sqrt(n[n_t])
  resids <- resid(ols_i)
  SSR_DT[i,n_t] <- sum(resids^2)/(n[n_t]-2)  # SSR/(n-k)
}
}

## Visual inspection ##
## Mean 
par(mfrow = c(1,2), mar = c(4.3,5,1,2))
# beta_1
plot( apply(slope_DT, 2, mean) ~ n, type = "l",
     xlab = "The sample size",
     ylab = TeX(r'(The mean of $\hat{\beta}_1$)'), ylim = c(0.4,0.6), lwd = 1.5 )
abline(h=0.5, col = "blue", lwd = 0.3)
# beta_0
plot( apply(intercept_DT, 2, mean) ~ n, type = "l",
     xlab = "The sampe size",
     ylab = TeX(r'(The mean of $\hat{\beta}_0$)'), ylim = c(0.8,1.2), lwd = 1.5 ) 
abline(h=1, col = "blue", lwd = 0.3)

## Standard Deviation 
par(mfrow = c(1,2), mar = c(4.3,5,1,2))
# beta_1
plot( apply(slope_DT, 2, sd) ~ n, type = "l",
     xlab = "The sample size",
     ylab = TeX(r'(The standard deviation of $\hat{\beta}_1$)'), ylim = c(0,0.05), lwd = 1.5 )
abline(h=0.5, col = "blue",lwd = 0.1)
# beta_0
plot( apply(intercept_DT, 2, sd) ~ n, type = "l",
     xlab = "The sampe size",
     ylab = TeX(r'(The standard deviation of $\hat{\beta}_0$)'), ylim = c(0,0.3), lwd = 1.5 ) 
abline(h=1, col = "blue", lwd = 0.1)

# Summary statistics
# beta_1
est_slope <- data.table(slope_DT)
stargazer(est_slope, type = "text")
# beta_0
est_intercept <- data.table(intercept_DT)
stargazer(est_intercept, type = "text")


# reshape data for density plot
sympt_DT <- data.frame(sympt_DT)
colnames(sympt_DT) <- c("size1", "size2", "size3", "size4", "size5")
dat = melt(sympt_DT, variable.name="Size",value.name = "Num" )


P_density = ggplot(dat,aes(x=Num)) +
  geom_density(aes(fill=as.character(dat$Size),color=as.character(dat$Size)),alpha = 0.5,size=1,linetype="solid") + 
  labs(x = TeX(r'($\sqrt{n}(\hat{\beta}_1-\beta_1)$)'), y = "Density",title = NULL) +
  scale_color_discrete(name=NULL,
                          #breaks=c("size1","size2","size3","size4","size5"),
                          labels=c("size=20","size=40","size=200", "size=1000","size=9000")  ) +
  scale_fill_discrete(guide = "none") +
  theme(plot.title = element_text(size = 25,face = "bold", vjust = 0.5, hjust = 0.5),
        legend.title = element_blank(),
        legend.text = element_text(size = 11, face = "plain"),
        legend.position = 'right',
        legend.key.size = unit(0.5,'cm'),
        axis.line = element_line(size = 0.3,color="black"),           
        axis.ticks.x = element_line(color="black",size=0.3,lineend = 1),                 
        #axis.ticks.y = element_line(color="black",size=0.3,lineend = 1),
        axis.text.x = element_text(size = 11,face = "plain", vjust = 0.5, hjust = 0.5),
        axis.text.y = element_text(size = 11,face = "plain", vjust = 0.5, hjust = 0.5),
        axis.title.x = element_text(size = 13,face = "plain", vjust = 0.5, hjust = 0.5),
        axis.title.y = element_text(size = 13,face = "plain", vjust = 0.5, hjust = 0.5),
        panel.background = element_rect(fill = "transparent",colour = NA), 
        panel.grid.minor = element_blank(), 
        panel.grid.major = element_blank(),
        plot.background = element_rect(fill = "transparent",colour = NA)) 

print(P_density)

## the normal distribution that the estimator converges in distribution to
asmptt <- P_density + geom_function(fun = dnorm, args = list(mean=0, sd=sqrt(1/18)), size=1.3)

print(asmptt)

```
```{r OLS-Monte Carlo: RSS/(n-k) is an unbiased estimator of sigma^2}
## Parameters and seed
beta_0 = 1   # Intercept 
beta_1 = 0.5 # Slope
set.seed(10) # Seed
M = 500      # Number of experiments/iterations
n = seq(from=100, to=5000, by=100)  # the test sample sizes
N = length(n)                       # count them
## Storage 
slope_DT <- matrix(NA, M, N)
intercept_DT <- matrix(NA, M, N)
sympt_DT <- matrix(NA, M, N)
SSR_DT <- matrix(NA, M, N) # SSR/(n-k)

## Begin Monte Carlo
for (n_t in 1:N){
for (i in 1:M){ # M is the number of iterations
  
  # Generate data
  U_i = runif(n[n_t], min = -1, max = 1) # Error
  X_i = rchisq(n[n_t], df = 3)           # Independent variable
  Y_i = beta_0 + beta_1*X_i + U_i        # Dependent variable
  
  # Formulate data.table
  data_i = data.table(Y = Y_i, X = X_i)
  
  # Run regressions
  ols_i <- fixest::feols(data = data_i, Y ~ X)
  
  # Extract slope coefficient and save
  slope_DT[i,n_t] <- ols_i$coefficients[2]
  intercept_DT[i,n_t] <- ols_i$coefficients[1]
  sympt_DT[i,n_t] <- (ols_i$coefficients[2]-beta_1)*sqrt(n[n_t])
  resids <- resid(ols_i)
  SSR_DT[i,n_t] <- sum(resids^2)/(n[n_t]-2)  # SSR/(n-k)
}
}

## Visual inspection ##
## Mean of RSS/(n-k)
par(mfrow = c(1,1), mar = c(4.3,5,1,2))
plot( apply(SSR_DT, 2, mean) ~ n, type = "l",
     xlab = "The sampe size",
     ylab = TeX(r'(The mean of $RSS/(n-k)$)'), ylim = c(0.325,0.34), lwd = 1.5 ) 
abline(h=1/3, col = "blue", lwd = 0.2)

# Summary statistics
est_slope <- data.table(SSR_DT)
stargazer(est_slope, type = "text")

```

